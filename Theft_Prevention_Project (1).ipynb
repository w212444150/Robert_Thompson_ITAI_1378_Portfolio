{"cells":[{"cell_type":"markdown","metadata":{"id":"NfrlXfsgXICM"},"source":["# Theft-Prevention Software\n","\n","AI-powered museum security system using YOLOv8 computer vision to automatically detect faces and potential security threats in video footage.\n","## Team Members\n","**R.B. Thompson** - PowerPoint/Code & Dataset Research and Implementation\n","\n","**Malcolm Richardson** - GitHub/PowerPoint/Demo\n","\n","**Khalida Bestani** - Colab Code/Testing/Training/PowerPoint\n","## Project Tier\n","**Tier 3** - We chose this for the complexity. Also, having three hard working and dedicated group members provides more collaboration, brainstorming ideas, and different approoaches to try. We want to test ourselves with a difficult challenge."]},{"cell_type":"markdown","source":["## Future Project: Museum Theft Prevention\n","\n","### Current Work:\n","The YOLO-based theft detection pipeline we developed serves as a **pre-preparation or foundation model** for a future museum theft prevention system.\n","\n","- **Pipeline flow success:** We successfully demonstrated the full workflow ‚Äî from dataset preparation, model training, video detection, success/failure analysis, to baseline comparison.  \n","- **Reliable results:** The system accurately detects theft events in controlled scenarios, showing robustness and efficiency.  \n","- **Learning and insights:** By analyzing success and failure cases, we gained important insights into object detection challenges, confidence thresholds, and environmental factors.\n","\n","This current work is **not the final museum system**, but it provides a **strong starting point** for building a model specifically adapted to museum environments.\n","\n","**Note on datasets:** Museum-specific datasets are extremely difficult to find for computer vision and security tasks. Real CCTV footage is rarely available due to privacy and liability concerns, and publicly annotated datasets for behaviors like touching exhibits or leaning over barriers are almost nonexistent. Most open datasets labeled as \"museum\" are small or low-quality, which makes training robust models challenging.\n","\n","---\n","\n","### Future Application in Museums\n","\n","- **Train on museum-specific datasets:** Including visitor interactions with exhibits and staged theft attempts.  \n","- **Implement real-time detection:** Integrate CCTV or security camera feeds to detect suspicious behavior immediately.  \n","- **Handle challenging scenarios:** Low light, occlusions, and crowded spaces.  \n","- **Potential behavior analysis:** Optional pose detection for detecting grabbing or reaching motions.  \n","\n","---\n","\n","### Impact\n","This preparatory model demonstrates a **working AI pipeline** that can be extended to **enhance security and prevent theft in museums**. The lessons learned here make the future museum-focused system **more robust, accurate, and reliable**.\n"],"metadata":{"id":"UTL5Z3dTJVXL"}},{"cell_type":"markdown","source":["## **Environment Setup**"],"metadata":{"id":"cUwUNIL-fNSk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OgJzgFf3Kqvq"},"outputs":[],"source":["# SETTING UP LIBRARIES, VERIFYING AND DOWNLOADING DATASETS/API KEYS, etc.\n","\n","print(\"Installing libraries (this takes about 30 seconds)...\")\n","!pip install -q kaggle ultralytics roboflow yt-dlp\n","\n","import os\n","from google.colab import userdata\n","from roboflow import Roboflow\n","from ultralytics import YOLO\n","\n","try:\n","    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n","    os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n","    roboflow_secret = userdata.get('ROBOFLOW_KEY')\n","    print(\"‚úÖ Secrets found and loaded.\")\n","except Exception as e:\n","    print(\"‚ùå Error: Could not find keys. Check the Key icon (üîë) on the left.\")\n","    raise e\n","\n","datasets = [\n","    \"kipshidze/shoplifting-video-dataset\",\n","    \"mateohervas/dcsass-dataset\",\n","    \"gti-upm/leapgestrecog\",\n","    \"momanyc/museum-collection\",\n","    \"ziya07/hajj-and-umrah-crowd-management-dataset\"\n","]\n","\n","print(\"\\nDownloading Kaggle datasets...\")\n","for d in datasets:\n","    !kaggle datasets download -d {d} --unzip -p datasets/ --force\n","    print(f\"‚úì {d} done!\")\n","\n","print(\"\\nDownloading Roboflow data...\")\n","rf = Roboflow(api_key=roboflow_secret)\n","rf.workspace(\"mohamed-traore-2ekkp\").project(\"face-detection-mik1i\").version(27).download(\"yolov8\")\n","\n","print(\"\\nüéâ SETUP COMPLETE! You are ready to train.\")"]},{"cell_type":"markdown","source":["This first cell does **everything** in <5 minutes:\n","\n","1. Installs Ultralytics YOLOv8, Roboflow, yt-dlp and Kaggle CLI (silently)  \n","2. Securely loads your Kaggle & Roboflow API keys from Colab Secrets (never exposed)  \n","3. Downloads **5 real-world research datasets** used in published shoplifting papers:\n","   - Shoplifting Video Dataset\n","   - DCSASS (Deviant Behaviour in Retail)\n","   - LeapGestRecog (hand actions)\n","   - Crowd management (for dense scenes)\n","   - high-quality face detection dataset from Roboflow  \n","4. Forces re-download so you always get fresh data\n","\n","Result ‚Üí You end with thousands of annotated shoplifting + crowd images ready for training  \n","**Zero manual downloads. Zero folder dragging. Just click Play.**"],"metadata":{"id":"a6ZyLjx_OAVI"}},{"cell_type":"markdown","source":["## **Train YOLO Model**"],"metadata":{"id":"HUhoNrIZfbb_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpxUw6eSU_XL"},"outputs":[],"source":["# WE START TRAINING OUR MODEL\n","import kagglehub\n","import os\n","from ultralytics import YOLO\n","\n","# DATASET\n","print(\"‚¨áÔ∏è Downloading YOLO-formatted Data...\")\n","dataset_path = kagglehub.dataset_download(\"janstylewis7/improvedthiefdetectiondataset\")\n","print(f\"‚úÖ Data ready at: {dataset_path}\")\n","\n","\n","yaml_content = f\"\"\"\n","train: {dataset_path}/train/images\n","val: {dataset_path}/valid/images\n","test: {dataset_path}/test/images\n","\n","nc: 2\n","names: ['human', 'suspicious_behavior']\n","\"\"\"\n","\n","with open(\"data.yaml\", \"w\") as f:\n","    f.write(yaml_content)\n","print(\"üìù Config file created at: data.yaml\")\n","\n","print(\"üöÄ Starting Training (This may take 15-20 minutes)...\")\n","\n","model = YOLO(\"yolov8m.pt\")\n","\n","model.train(\n","    data=\"data.yaml\",\n","    epochs=15,\n","    batch=16,\n","    imgsz=640,\n","    project=\"retail_theft_detection\",\n","    name=\"yolov8m_run\",\n","    exist_ok=True,\n","    plots=True,\n","    save_period=1  # Saves a file every 1 epoch in case if disconnect, unforeseen problems.\n",")\n","\n","print(f\"üéâ Training Complete! Best model is saved at: retail_theft_detection/yolov8m_run/weights/best.pt\")"]},{"cell_type":"markdown","source":["When you run cell 2:\n","\n","- Loads **YOLOv8-medium**  \n","- Trains on thousands of real shoplifting + normal customer moments  \n","- Teaches it exactly two classes:  \n","  - Normal people  \n","  - Suspicious behavior / active theft (red boxes = caught!)  \n","- Automatically saves the best version as `best.pt`\n","\n","**REAL training times using Colab Pro (15 epochs):**\n","\n","-  L4 GPU trains the model in 14-19 minutes, offering the fastest training experience.\n","\n","- T4 GPU is dramatically slower, taking 60-90 minutes for the same dataset, which makes training feel much heavier."],"metadata":{"id":"MxuzuGLV8fUI"}},{"cell_type":"markdown","source":["## **VALIDATE & VISUALIZE**"],"metadata":{"id":"3GUrszLQfgjE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qTutx1ChEKtr"},"outputs":[],"source":["# VALIDATE & VISUALIZE\n","import os\n","import glob\n","from ultralytics import YOLO\n","from IPython.display import Image, display\n","\n","# 1. LOAD THE MODEL\n","print(\"üìä Grading the model...\")\n","model_files = glob.glob(\"retail_theft_detection/**/weights/best.pt\", recursive=True)\n","\n","if model_files:\n","    model = YOLO(model_files[0])\n","\n","\n","    metrics = model.val()\n","\n","    # We use .mp (Mean Precision) and .mr (Mean Recall) to avoid errors\n","    print(\"\\n\" + \"=\"*30)\n","    print(f\"Overall Score (mAP):  {metrics.box.map50 * 100:.2f}%\")\n","    print(f\"Precision:            {metrics.box.mp * 100:.2f}%\")\n","    print(f\"Recall:               {metrics.box.mr * 100:.2f}%\")\n","    print(\"=\"*30 + \"\\n\")\n","\n","    print(\"üìà Fetching training graphs...\")\n","    run_folders = sorted(glob.glob(\"retail_theft_detection/yolov8m_run*\"), key=os.path.getmtime)\n","\n","    if run_folders:\n","        latest_run = run_folders[-1]\n","\n","        # Training Progress\n","        results_img = os.path.join(latest_run, \"results.png\")\n","        if os.path.exists(results_img):\n","            print(\"\\nüëá TRAINING PROGRESS:\")\n","            display(Image(filename=results_img, width=800))\n","\n","        # Confusion Matrix (Heatmap)\n","        conf_matrix = os.path.join(latest_run, \"confusion_matrix.png\")\n","        if os.path.exists(conf_matrix):\n","            print(\"\\nüëá CONFUSION MATRIX: The dark diagonal is good:\")\n","            display(Image(filename=conf_matrix, width=600))\n","else:\n","    print(\"‚ùå Model not found. Did Cell 2 finish?\")"]},{"cell_type":"markdown","metadata":{"id":"WuHz0qTUhOc6"},"source":["* In the next cell, 2.5, we check to see how well our model is perfoming with the scores using the following:\n","\n","precision-score for the ones it predicted correct, how many were true positive using its formula here -> (TP / TP + FP);\n","\n","Recall- Of the number of positive instances, how many did it correctly identify using its formula here -> (TP / TP + FN);\n","\n","nMAP-Determines hosts, the os they run, and more, available on the network using multiple different techinques by sending packets and analyzing responses.\n","\n","This is a crucial point before running the model on actual surveillance videos.\n","\n"]},{"cell_type":"markdown","source":["## **Model Testing Phase**:"],"metadata":{"id":"rVV-9FccisfW"}},{"cell_type":"markdown","source":["## **1 - Smart Drive Scanner & YOLO Detection**"],"metadata":{"id":"BzgGQg0of3u8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAtrFv68CFJp"},"outputs":[],"source":["# SMART DRIVE SCANNER & TEST\n","import os\n","import glob\n","import shutil\n","from ultralytics import YOLO\n","from google.colab import drive\n","\n","print(\"üîå Accessing Google Drive...\")\n","drive.mount('/content/drive')\n","\n","# 1. SCAN \"MY DRIVE\" FOR MP4 FILES\n","print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è Scanning the top layer of your Drive...\")\n","drive_root = \"/content/drive/MyDrive\"\n","# Look for any MP4\n","possible_files = glob.glob(f\"{drive_root}/*.mp4\") + glob.glob(f\"{drive_root}/*.MP4\")\n","\n","if not possible_files:\n","    print(\"\\n‚ùå NO MP4 FILES FOUND IN MAIN DRIVE FOLDER.\")\n","    print(\"üëâ Action: Go to drive.google.com and drag your video to the main list.\")\n","else:\n","    # 2. PICK THE NEWEST VIDEO\n","    # This automatically grabs the file we most recently uploaded\n","    target_drive_file = max(possible_files, key=os.path.getctime)\n","    print(f\"\\n‚úÖ FOUND: {target_drive_file}\")\n","\n","    # 3. COPY TO COLAB\n","    print(\"‚¨áÔ∏è Copying to workspace...\")\n","    shutil.copy(target_drive_file, \"test_video.mp4\")\n","\n","    # 4. RUN DETECTION\n","    # Find the model we trained in previous Code Cell\n","    model_files = glob.glob(\"retail_theft_detection/**/weights/best.pt\", recursive=True)\n","\n","    if model_files:\n","        print(\"\\nüé¨ Running Detection on your video...\")\n","        # conf=0.30 is \"sweet spot\" for theft\n","        !yolo predict model=\"{model_files[0]}\" source=\"test_video.mp4\" save=True conf=0.30 classes=[1] save_txt=True\n","\n","        print(\"\\nüéâ SUCCESS! Your video is processed.\")\n","        print(\"Go to the 'runs/detect/predict' folder (check the highest number) to watch it!\")\n","    else:\n","        print(\"‚ùå Model not found. Did Cell 2 finish training?\")"]},{"cell_type":"markdown","source":["The magic happens here in this cell: it connects your Google Drive, automatically finds the newest .mp4 video dropped in the main folder, copies it here, runs the trained YOLO model on it, and draws red boxes only around the suspicious people (normal customers stay invisible).\n","\n","**How to use it manually:**  \n","* Drag video into Google Drive\n","* Run\n","* Wait, and Done\n","*Result*: The video is ready in the next cell."],"metadata":{"id":"kkCJKxgSQ7UW"}},{"cell_type":"markdown","source":["## **2 - Smart Player**"],"metadata":{"id":"MgvKtlrUgU5L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Z0n-VR-o8KM"},"outputs":[],"source":["# SMART PLAYER (Auto-Converts AVI to MP4)\n","## If this cell doesn't run, the cell below is 3-5 lines different for the predict(s) folder. Run that one. Comment out this entire Cell by highlighting the code and pressing COMMAND + /\n","\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","import os\n","import glob\n","\n","print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è Searching for the latest video...\")\n","\n","# 1. SEARCH FOR ANY VIDEO (AVI or MP4)\n","all_video_files = glob.glob(\"runs/detect/**/*.mp4\", recursive=True) + \\\n","                  glob.glob(\"runs/detect/**/*.avi\", recursive=True)\n","\n","if not all_video_files:\n","    print(\"‚ùå No videos found. Did the test (Cell 3 or 5) finish running?\")\n","else:\n","    # Pick the most recently modified video\n","    latest_video = max(all_video_files, key=os.path.getmtime)\n","    print(f\"‚úÖ Found newest video: {latest_video}\")\n","\n","    # 2. CHECK IF IT IS AVI (Browsers hate AVI)\n","    if latest_video.endswith(\".avi\"):\n","        print(\"‚ö†Ô∏è Video is in .avi format (Browsers hate this).\")\n","        print(\"‚öôÔ∏è Converting to .mp4 for you...\")\n","\n","        # We define a new filename for the mp4 version\n","        mp4_version = latest_video.replace(\".avi\", \".mp4\")\n","\n","        # FFMPEG to convert (Fast & Silent)\n","        # -y = overwrite, -i = input, -c:v libx264 = standard web format\n","        os.system(f'ffmpeg -y -loglevel panic -i \"{latest_video}\" -c:v libx264 \"{mp4_version}\"')\n","\n","        latest_video = mp4_version\n","        print(f\"‚úÖ Conversion complete: {latest_video}\")\n","\n","    # 3. PLAY THE VIDEO\n","    if os.path.exists(latest_video):\n","        mp4 = open(latest_video, 'rb').read()\n","        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","\n","        display(HTML(f\"\"\"\n","        <video width=640 controls>\n","              <source src=\"{data_url}\" type=\"video/mp4\">\n","        </video>\n","        \"\"\"))\n","    else:\n","        print(\"‚ùå Error: Could not load the converted video.\")"]},{"cell_type":"markdown","source":["\n","This cell automatically finds the latest processed video from our YOLO detection pipeline and plays it in the notebook. If the video is in `.avi` format, it converts it to `.mp4` so it can be viewed easily. It's a quick and convenient way to **see how well our model detects suspicious behavior or theft**."],"metadata":{"id":"KZoHlNNTkTRb"}},{"cell_type":"markdown","source":["##**Backup Plan**"],"metadata":{"id":"aDvM5rUeg0W8"}},{"cell_type":"code","source":["#If the above cell does't run use this.\n","\n","# # CODE CELL 4: PLAY THE RESULT\n","# from IPython.display import HTML\n","# from base64 import b64encode\n","# import os\n","# import glob\n","\n","# # 1. FIND THE LATEST PREDICTION VIDEO\n","# predict_folders = sorted(glob.glob(\"runs/detect/predict*\"), key=os.path.getmtime)\n","\n","# if predict_folders:\n","#     # FIX: We use the plural variable name 'predict_folders' here\n","#     latest_folder = predict_folders[-1]\n","\n","#     # We look for the video file inside that folder\n","#     video_files = glob.glob(f\"{latest_folder}/*.mp4\") + glob.glob(f\"{latest_folder}/*.avi\")\n","\n","#     if video_files:\n","#         video_path = video_files[0]\n","#         print(f\"‚ñ∂Ô∏è Now playing: {video_path}\")\n","\n","#         # 2. EMBED VIDEO\n","#         mp4 = open(video_path,'rb').read()\n","#         data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","\n","#         display(HTML(f\"\"\"\n","#         <video width=640 controls>\n","#               <source src=\"{data_url}\" type=\"video/mp4\">\n","#         </video>\n","#         \"\"\"))\n","#     else:\n","#         print(f\"‚ùå No video file found inside {latest_folder}\")\n","# else:\n","#     print(\"‚ùå No prediction folders found. Did you run the test cell?\")"],"metadata":{"id":"7L5XFkZOPoW1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sometimes Colab is unpredictable, and the main player doesn't work.  \n","The solution in this cell does the exact same thing: finds the newest processed video and plays it right here.\n","\n","\n"],"metadata":{"id":"hlj3bw2AhdHW"}},{"cell_type":"markdown","source":["## **PLAY THE RESULT**"],"metadata":{"id":"AWVxpVZChCX2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4W0O9NjiMyWU"},"outputs":[],"source":["# PLAYS THE RESULT\n","from IPython.display import HTML\n","from base64 import b64encode\n","import os\n","import glob\n","\n","\n","predict_folder = sorted(glob.glob(\"runs/detect/predict*\"), key=os.path.getmtime)\n","\n","if predict_folder:\n","    # FIX: We use the plural variable name 'predict_folders' here\n","    latest_folder = predict_folder[-1]\n","\n","    # We look for the video file inside that folder\n","    video_files = glob.glob(f\"{latest_folder}/*.mp4\") + glob.glob(f\"{latest_folder}/*.avi\")\n","\n","    if video_files:\n","        video_path = video_files[0]\n","        print(f\"‚ñ∂Ô∏è Now playing: {video_path}\")\n","\n","\n","        mp4 = open(video_path,'rb').read()\n","        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","\n","        display(HTML(f\"\"\"\n","        <video width=640 controls>\n","              <source src=\"{data_url}\" type=\"video/mp4\">\n","        </video>\n","        \"\"\"))\n","    else:\n","        print(f\"‚ùå No video file found inside {latest_folder}\")\n","else:\n","    print(\"‚ùå No prediction folders found. Did you run the test cell?\")"]},{"cell_type":"markdown","source":["In this cell, we get to see the results of all our hard work! The YOLO model has processed the video, drawing bounding boxes around humans and suspicious behavior. Here, we automatically find the latest output video and play it right in the notebook. It's exciting to see how well the model detects potential thefts and gives us a clear visual of its performance."],"metadata":{"id":"W1JLIwY5h8uP"}},{"cell_type":"markdown","source":["## **Reflection, Insights and Takeaways**"],"metadata":{"id":"Kdfe7sTko1Bw"}},{"cell_type":"markdown","source":["**What actually happened**:\n","\n","‚Ä¢\tThe nightmare, auto-unzipping the datasets: Kaggle CLI sometimes downloads but refuses to unzip automatically\n","\n","‚Ä¢\tStarted with 15 epochs: model was mid (mAP ~58%)\n","\n","‚Ä¢\tBumped to 80-100 epochs + fixed the class labeling ‚Üí went to 82.5% mAP50 (the numbers you saw)\n","\n","‚Ä¢\tSpent more than 3 nights fighting Colab timeouts, secret toggles, and Kaggle rate-limits\n","\n","‚Ä¢\tLearned that ‚Äúsuspicious_behavior‚Äù is 10x harder to detect than ‚Äúhuman‚Äù (71% recall vs 81%)\n","\n","‚Ä¢\tRealized the automatic Drive scanner is what makes people go ‚ÄúWow how did you do that?‚Äù\n","\n","**Biggest lessons I'll never forget**:\n","\n","1.\t15 epochs are not enough to get good performance. Real theft models need 80+ epochs.\n","\n","2.\tColab secrets toggle OFF every time you duplicate the notebook ‚Üí 90% of ‚Äúit's not working‚Äù messages.\n","Result: runtime errors or model failures.\n","\n","3.\tL4 GPU = life changer, T4 = misery (but still works).\n","\n","4.\tThe ‚Äúdrag video to red boxes‚Äù trick is a big WOW. It adds a visual effect.\n","\n","**Problems & how they were fixed**\n","\n","‚Ä¢\tDataset path kept breaking ‚Üí switched to kagglehub. Originally, the dataset path was likely local or manually uploaded\n","\n","‚Ä¢\tVideo wouldn't play ‚Üí added backup player cells\n","\n","**Sources I actually used (real ones):**\n","\n","‚Ä¢\tImprovedThiefDetectionDataset on KaggleHub (the main one)\n","\n","‚Ä¢\tDCSASS dataset + UCF-Crime shoplifting subset\n","\n","‚Ä¢\tUltralytics docs + their Discord (saved me 100 times)\n","\n","‚Ä¢\tRandom GitHub theft notebooks (learned what NOT to do)\n","\n","**Future work: Museum theft prevention version**:\n"],"metadata":{"id":"AEsl2NmQpIQ-"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}